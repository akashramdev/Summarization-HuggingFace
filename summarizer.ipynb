{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.29.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.5.5)\n",
      "Requirement already satisfied: requests in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2022.12.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Intsall transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "from transformers import pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Summarization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a367f84b1ae4c1098d669408a260d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\acer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\acer\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d5a0f49ac045fd8300569245a837d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e3f464548a44f992eef69debe23e83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e2b936e7fc94632aa446f69cbea1280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dae85831c7d041b08f6a4ddb35876b11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a blog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://towardsdatascience.com/a-bayesian-take-on-model-regularization-9356116b6457\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(r.text, 'html.parser')\n",
    "results = soup.find_all(['h1', 'p'])\n",
    "text = [result.text for result in results]\n",
    "ARTICLE = ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sign up Sign In Sign up Sign In Member-only story A Bayesian Take On Model Regularization Ryan Sander Follow Towards Data Science -- 1 Listen Share I’m currently reading “How We Learn” by Stanislas Dehaene. First off, I cannot recommend this book enough to anyone interested in learning, teaching, or AI. One of the main themes of this book is explaining the neurological and psychological bases of why humans are so good at learning things quickly and with great sample-efficiency, i.e. given only a limited amount of experience¹. One of Dehaene’s main arguments of why humans can learn so effectively is because we are able to reduce the complexity of models we formulate of the world. In accordance with the principle of Occam’s Razor², we find the simplest model possible that explains the data we experience, rather than opting for more complicated models. But why do we do this, even from birth¹? One argument is that, contrary to the frequentist view in child psychology (the belief that babies learn solely through their experiences), we are already imparted with prior beliefs about the world when we are born¹. This notion of simplified model selection has a common name in the field of machine learning: model regularization. In this article, we’ll talk about regularization from a Bayesian perspective. What’s one way we can control the complexity of the models we learn from observations? We can do this by placing a prior on our distribution of models. Before we show this, let’s briefly go over regularization, in this case, analytic regularization for supervised learning. Background on Regularization In machine learning, regularization, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance, even if the distribution of out-of-sample data (test/validation data) differs significantly from the distribution of in-sample data (training data). In essence, the model must balance having a small empirical loss (how “wrong” it is on the data it is given) with a small regularization loss (how complicated the model is). In supervised learning, regularization is usually accomplished via L2 (Ridge)⁸, L1 (Lasso)⁷, or L2/L1 (ElasticNet)⁹ regularization. For neural networks, there are also techniques such as Drop-out³ or Early Stopping⁴. For now, we will focus on analytical regularization techniques, since their Bayesian interpretation is more well-defined. These techniques are summarized below. Let’s start by defining our dataset and parameters: Next, for a given supervised learning problem in which we wish to minimize a loss function (e.g. Mean-Squared Error): Then we have the following objectives for each type of analytical supervised regularization techniques: Below is a comparative plot showing the norm plots of Lasso, ElasticNet, and Ridge regularization, each drawn over a unit sphere. The code to generate this plot can be found in the Appendix. In summary, these regularization techniques accomplish different objectives for controlling the complexity of our models. In the next section, we will derive these regularized objectives by imposing a prior belief (in the form of a probability distribution) on our model parameters, thus directly making the link between prior beliefs and model regularization. Model Regularization as a Prior Belief on Models Let’s dive deeper into the probabilistic and optimization theory behind implementing regularization through a prior belief in our model parameters. Specifically, we will demonstrate that: We will analyze these claims for regression problems, but they extend to other supervised learning tasks, such as classification, as well. We’ll focus on rigorously presenting the mathematics behind these claims (you can also find these derivations in this document here). Let’s dive in! L2 (Ridge) Regularization as a Multivariate Gaussian Prior Suppose we again have the same set of observations D and a parameter vector w that we want to optimize in order to best make predictions on samples from D: Using the Maximum a Posteriori (MAP) rule, we can show that the mean and mode of the posterior distribution of w is the solution for ridge regression when we invoke a Gaussian prior distribution on w. We first invoke Bayes’ Rule: We now define our prior and observation model distributions, with the following assumptions: a. Prior Model (distribution over parameters w): b. Observation Model (conditional distribution of observations D conditioned on parameters): Now, let’s substitute these expressions into Bayes’ Rule: To derive our L2 regularized estimator, we now use the MAP rule and the negative log-likelihood function to transform this expression over products into an expression over sums. This operation is permissible because: (i) The logarithm of the objective is a strictly monotonic transformation of the likelihood function, and thus taking the maximum argument of the log-likelihood function will preserve the cardinality of the likelihood objective and yield the same maximizing argument. (ii) The maximizing argument of any objective J(θ) is the same as the minimizing argument of the negative objective -J(θ). Therefore, the argument w* that maximizes the log-likelihood will minimize the negative log-likelihood: Substituting our posterior distribution into our expression for negative log-likelihood: Since logarithms transform products into sums, we can decompose this logarithm of products into a sum of summation terms that depend on our parameters w, along with constants that do not depend on w. We can then use logarithm rules to simplify this expression. Removing terms that don’t depend on our parameters w, multiplying the expression by a constant σ², we obtain: The setting of λ = σ² / τ yields that our MAP estimator is also the estimator obtained via ridge regression (when our data is centered around 0): This corresponds exactly to our ridge objective (for regression) above! In closed-form, this yields the normal equations: Where the λI term is used to ensure that the matrix to be inverted (X^T X) is positive semi-definite, and therefore invertible. Therefore, placing a Multivariate Gaussian prior on our parameters is equivalent to regularizing our parameters with an L2-norm penalty. We’ll now examine a similar case with a Laplace prior. Suppose again that we have a dataset of observations D and a parameter vector w that we want to optimize in order to best make predictions on samples from D: Again using the MAP rule, we can show that the mean and mode of the posterior distribution of w is the solution for LASSO regression when we invoke a Gaussian prior distribution on w. We first invoke Bayes’ Rule: We now define our prior and observation model distributions, with the following assumptions: a. Prior Model (distribution over parameters w): b. Observation Model (Same distribution as above): Repeating the same steps as above (referenced below): Here is the corresponding derivation for Lasso: (Note that in the last step, we set p = 1, q = 1, and λ = α_1 / α_2.) As before, we have derived our Lasso objective (for regression) as described in the section above! Why Does This Matter? Though it may seem like all we did was invoke some tricks with optimization, logarithms, and probability distributions, the significance of the above derivations may be best understood in the context of the aforementioned novel “How We Learn”. If I, a human being, am learning a model of the world, why do I tend towards the simplest model that explains my observations¹? One reason for this is because our brain creates “prior beliefs” over the models we learn even before we learn them, which we take into account when we learn from experience. Rather than learning these models only from experience, however, we use experience to update our previous beliefs of these models. By placing a prior belief that the models we learn must be as simple as possible, we are able to control the complexity of the models we learn even before we learn them! This is exactly what we have done with our analytic derivations above: by placing a prior belief on the distribution of our model parameters (i.e. “the model parameters w are normally-distributed”) we are able to directly shape how complex these models are. Summary In this article, we introduced the ideas of model complexity and regularization, and how these concepts relate to the idea of prior beliefs. We made the claim that we can control the complexity of a model, i.e. regularize it, by setting a prior belief on our distribution of parameters. We then briefly introduced some common analytical, supervised regularization techniques (Ridge, Lasso, and ElasticNet regression). We then showed how we can derive the objective functions for Ridge and Lasso regularization using Multivariate Gaussian and Laplace prior distributions, respectively. Finally, we talked about why these results are significant not only for machine learning, but for psychology as well. Thanks for reading :) Please follow me for more articles in reinforcement learning, computer vision, programming, and optimization! Also, a huge thank you to CODECOGS for their online equation rendering tool! It’s very helpful and easy to use if you want to render mathematics in your Medium articles. References [1] Dehaene, Stanislas. How we learn: Why brains learn better than any machine… for now. Penguin, 2020. [2] Rasmussen, Carl Edward, and Zoubin Ghahramani. “Occam’s razor.” Advances in neural information processing systems (2001): 294–300. [3] Srivastava, Nitish, et al. “Dropout: a simple way to prevent neural networks from overfitting.” The journal of machine learning research 15.1 (2014): 1929–1958. [4] Caruana, Rich, Steve Lawrence, and Lee Giles. “Overfitting in neural nets: Backpropagation, conjugate gradient, and early stopping.” Advances in neural information processing systems (2001): 402–408. [5] Tibshirani, Robert. “Regression shrinkage and selection via the lasso.” Journal of the Royal Statistical Society: Series B (Methodological) 58.1 (1996): 267–288. [6] Calvetti, Daniela, and Lothar Reichel. “Tikhonov regularization of large linear problems.” BIT Numerical Mathematics 43.2 (2003): 263–283. [7] Tibshirani, Robert. “Regression shrinkage and selection via the lasso.” Journal of the Royal Statistical Society: Series B (Methodological) 58.1 (1996): 267–288. [8] Hoerl, Arthur E., and Robert W. Kennard. “Ridge regression: Biased estimation for nonorthogonal problems.” Technometrics 12.1 (1970): 55–67. [9] Zou, Hui, and Trevor Hastie. “Regularization and variable selection via the elastic net.” Journal of the royal statistical society: series B (statistical methodology) 67.2 (2005): 301–320. Appendix Code to generate plots (adapted from this Stack OverFlow post). -- -- 1 Towards Data Science Image Scientist, MIT CSAIL Alum, Tutor, Dark Roast Coffee Fan, GitHub: https://github.com/rmsander/ Ryan Sander in Towards Data Science -- 2 Jacob Marks, Ph.D. in Towards Data Science -- 30 Leonie Monigatti in Towards Data Science -- 13 Ryan Sander in Towards Data Science -- 2 Luís Roque in Towards Data Science -- 2 Leihua Ye, PhD -- 9 Egor Howell in Towards Data Science -- Molly Ruby in Towards Data Science -- 125 Matt Chapman in Towards Data Science -- 44 Aashish Nair in Towards Data Science -- Help Status Writers Blog Careers Privacy Terms About Text to speech'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTICLE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_chunk = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTICLE = ARTICLE.replace('.', '.<eos>')\n",
    "ARTICLE = ARTICLE.replace('?', '?<eos>')\n",
    "ARTICLE = ARTICLE.replace('!', '!<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sentences = ARTICLE.split('<eos>')\n",
    "current_chunk = 0 \n",
    "chunks = []\n",
    "for sentence in sentences:\n",
    "    if len(chunks) == current_chunk + 1: \n",
    "        if len(chunks[current_chunk]) + len(sentence.split(' ')) <= max_chunk:\n",
    "            chunks[current_chunk].extend(sentence.split(' '))\n",
    "        else:\n",
    "            current_chunk += 1\n",
    "            chunks.append(sentence.split(' '))\n",
    "    else:\n",
    "        print(current_chunk)\n",
    "        chunks.append(sentence.split(' '))\n",
    "\n",
    "for chunk_id in range(len(chunks)):\n",
    "    chunks[chunk_id] = ' '.join(chunks[chunk_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks[1].split(' '))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = summarizer(chunks, max_length=120, min_length=30, do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_text': ' In machine learning, regularization, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance . We can do this by placing a prior on our distribution of models . The Bayesian approach is called analytic regularization for supervised learning .'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_text': ' We will analyze these claims for regression problems, but they extend to other supervised learning tasks, such as classification, as well . We will focus on rigorously presenting the mathematics behind these claims . In the next section, we will use Bayes’ Rule to derive our L2 regularized estimator .'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In machine learning, regularization, or model complexity control, is an essential and common practice to ensure that a model attains high out-of-sample performance . We can do this by placing a prior on our distribution of models . The Bayesian approach is called analytic regularization for supervised learning .  We will analyze these claims for regression problems, but they extend to other supervised learning tasks, such as classification, as well . We will focus on rigorously presenting the mathematics behind these claims . In the next section, we will use Bayes’ Rule to derive our L2 regularized estimator .  Using Bayes’ Rule, we can show that the mean and mode of the posterior distribution of w is the solution for LASSO regression when we invoke a Gaussian prior distribution on w . We’ll now examine a similar case with a Laplace prior . Here is the corresponding derivation for Lasso: (Note that in the last step, we set p = 1, q = 1)  A huge thank you to CODECOGS for their online equation rendering tool! It’s very helpful and easy to use if you want to render mathematics in your Medium articles .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([summ['summary_text'] for summ in res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = ' '.join([summ['summary_text'] for summ in res])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save output to text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('summary.txt', 'w') as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
